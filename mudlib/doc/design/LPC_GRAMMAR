
varargs mixed *parse(string foo, int nalt)
{
    return parse_string("\
whitespace = /[ \t\n\r\v\f]+/						\
whitespace = /\\/\\*([^*]|\\*+[^/*])*\\*\\//				\
whitespace = /#[^\n]*\n/						\
"+"									\
INT_CONST = /[1-9][0-9]*/						\
INT_CONST = /0[0-7]*/							\
INT_CONST = /0[Xx][0-9a-fA-F]+/						\
INT_CONST = /'[^\\\\]'/							\
INT_CONST = /'\\\\[^0-7xX]'/						\
INT_CONST = /'\\\\[0-7][0-7]?[0-7]?'/					\
INT_CONST = /'\\\\[xX][0-9a-fA-F][0-9a-fA-F]?'/				\
FLOAT_CONST = /[0-9]+\\.[0-9]*([eE][-+]?[0-9]+)/			\
FLOAT_CONST = /[0-9]*\\.[0-9]+([eE][-+]?[0-9]+)/			\
STRING_CONST = /\"([^\\\\\"\n]*(\\\\.)*)*\"/				\
IDENTIFIER = /[a-zA-Z_][a-zA-Z_0-9]*/					\
"+"									\
program:								\
program: program top_level_declaration					\
"+"									\
top_level_declaration: 'inherit' opt_inherit_label inherit_string ';'	\
top_level_declaration: data_declaration					\
top_level_declaration: function_declaration				\
"+"									\
opt_inherit_label:							\
opt_inherit_label: IDENTIFIER						\
"+"									\
inherit_string: STRING_CONST						\
inherit_string: inherit_string '+' STRING_CONST				\
inherit_string: '(' inherit_string ')'					\
"+"									\
data_declaration: class_specifier_list type_specifier list_dcltr ';'	\
"+"									\
function_declaration: class_specifier_list type_specifier		\
		      function_dcltr compound_stmt			\
function_declaration: class_specifier_list				\
		      IDENTIFIER '(' formals_declaration ')'		\
		      compound_stmt					\
"+"									\
local_data_declaration: class_specifier_list type_specifier		\
			list_dcltr ';'					\
"+"									\
formals_declaration:							\
formals_declaration: 'void'						\
formals_declaration: formal_declaration_list				\
formals_declaration: formal_declaration_list '...'			\
"+"									\
formal_declaration_list: formal_declaration				\
formal_declaration_list: formal_declaration_list ',' formal_declaration	\
"+"									\
formal_declaration: type_specifier data_dcltr				\
formal_declaration: IDENTIFIER						\
"+"									\
class_specifier_list:							\
class_specifier_list: class_specifier_list class_specifier		\
"+"									\
class_specifier: 'private'						\
class_specifier: 'static'						\
class_specifier: 'atomic'						\
class_specifier: 'nomask'						\
class_specifier: 'varargs'						\
"+"									\
type_specifier: 'int'							\
type_specifier: 'float'							\
type_specifier: 'string'						\
type_specifier: 'object'						\
type_specifier: 'mapping'						\
type_specifier: 'mixed'							\
type_specifier: 'void'							\
"+"									\
star_list:								\
star_list: star_list '*'						\
"+"									\
data_dcltr: star_list IDENTIFIER					\
"+"									\
function_dcltr: star_list IDENTIFIER '(' formals_declaration ')'	\
"+"									\
dcltr: data_dcltr							\
dcltr: function_dcltr							\
"+"									\
list_dcltr: dcltr							\
list_dcltr: list_dcltr ',' dcltr					\
"+"									\
dcltr_or_stmt_list:							\
dcltr_or_stmt_list: dcltr_or_stmt_list dcltr_or_stmt			\
"+"									\
dcltr_or_stmt: local_data_declaration					\
dcltr_or_stmt: stmt							\
"+"									\
stmt: list_exp ';'							\
stmt: compound_stmt							\
stmt: 'if' '(' list_exp ')' stmt ? ifelse				\
stmt: 'if' '(' list_exp ')' stmt 'else' stmt ? ifelse			\
stmt: 'do' stmt 'while' '(' list_exp ')' ';'				\
stmt: 'while' '(' list_exp ')' stmt					\
stmt: 'for' '(' opt_list_exp ';' opt_list_exp ';' opt_list_exp ')' stmt	\
stmt: 'rlimits' '(' list_exp ';' list_exp ')' compound_stmt		\
stmt: 'catch' compound_stmt opt_caught_stmt				\
stmt: 'switch' '(' list_exp ')' compound_stmt				\
stmt: 'case' exp ':' stmt						\
stmt: 'case' exp '..' exp ':' stmt					\
stmt: 'default' ':' stmt						\
stmt: 'break' ';'							\
stmt: 'continue' ';'							\
stmt: 'return' opt_list_exp ';'						\
stmt: ';'								\
"+"									\
compound_stmt: '{' dcltr_or_stmt_list '}'				\
"+"									\
opt_caught_stmt:							\
opt_caught_stmt: ':' stmt						\
"+"									\
function_name: IDENTIFIER						\
function_name: '::' IDENTIFIER						\
function_name: IDENTIFIER '::' IDENTIFIER				\
"+"									\
primary_p1_exp: INT_CONST						\
primary_p1_exp: FLOAT_CONST						\
primary_p1_exp: STRING_CONST						\
primary_p1_exp: '(' '{' opt_arg_list_comma '}' ')'			\
primary_p1_exp: '(' '[' opt_assoc_arg_list_comma ']' ')'		\
primary_p1_exp: IDENTIFIER						\
primary_p1_exp: '(' list_exp ')'					\
primary_p1_exp: function_name '(' opt_arg_list ')'			\
primary_p1_exp: 'catch' '(' list_exp ')'				\
primary_p1_exp: primary_p2_exp '->' IDENTIFIER '(' opt_arg_list ')'	\
"+"									\
primary_p2_exp: primary_p1_exp						\
primary_p2_exp: primary_p2_exp '[' list_exp ']'				\
primary_p2_exp: primary_p2_exp '[' opt_list_exp '..' opt_list_exp ']'	\
"+"									\
postfix_exp: primary_p2_exp						\
postfix_exp: postfix_exp '++'						\
postfix_exp: postfix_exp '--'						\
"+"									\
prefix_exp: postfix_exp							\
prefix_exp: '++' cast_exp						\
prefix_exp: '--' cast_exp						\
prefix_exp: '-' cast_exp						\
prefix_exp: '+' cast_exp						\
prefix_exp: '!' cast_exp						\
prefix_exp: '~' cast_exp						\
"+"									\
cast_exp: prefix_exp							\
cast_exp: '(' type_specifier star_list ')' cast_exp			\
"+"									\
mult_oper_exp: cast_exp							\
mult_oper_exp: mult_oper_exp '*' cast_exp				\
mult_oper_exp: mult_oper_exp '/' cast_exp				\
mult_oper_exp: mult_oper_exp '%' cast_exp				\
"+"									\
add_oper_exp: mult_oper_exp						\
add_oper_exp: add_oper_exp '+' mult_oper_exp				\
add_oper_exp: add_oper_exp '-' mult_oper_exp				\
"+"									\
shift_oper_exp: add_oper_exp						\
shift_oper_exp: shift_oper_exp '<<' add_oper_exp			\
shift_oper_exp: shift_oper_exp '>>' add_oper_exp			\
"+"									\
rel_oper_exp: shift_oper_exp						\
rel_oper_exp: rel_oper_exp '<' shift_oper_exp				\
rel_oper_exp: rel_oper_exp '>' shift_oper_exp				\
rel_oper_exp: rel_oper_exp '<=' shift_oper_exp				\
rel_oper_exp: rel_oper_exp '>=' shift_oper_exp				\
"+"									\
equ_oper_exp: rel_oper_exp						\
equ_oper_exp: equ_oper_exp '==' rel_oper_exp				\
equ_oper_exp: equ_oper_exp '!=' rel_oper_exp				\
"+"									\
bitand_oper_exp: equ_oper_exp						\
bitand_oper_exp: bitand_oper_exp '&' equ_oper_exp			\
"+"									\
bitxor_oper_exp: bitand_oper_exp					\
bitxor_oper_exp: bitxor_oper_exp '^' bitand_oper_exp			\
"+"									\
bitor_oper_exp: bitxor_oper_exp						\
bitor_oper_exp: bitor_oper_exp '|' bitxor_oper_exp			\
"+"									\
and_oper_exp: bitor_oper_exp						\
and_oper_exp: and_oper_exp '&&' bitor_oper_exp				\
"+"									\
or_oper_exp: and_oper_exp						\
or_oper_exp: or_oper_exp '||' and_oper_exp				\
"+"									\
cond_exp: or_oper_exp							\
cond_exp: or_oper_exp '?' list_exp ':' cond_exp				\
"+"									\
exp: cond_exp								\
exp: cond_exp '=' exp							\
exp: cond_exp '+=' exp							\
exp: cond_exp '-=' exp							\
exp: cond_exp '*=' exp							\
exp: cond_exp '/=' exp							\
exp: cond_exp '%=' exp							\
exp: cond_exp '<<=' exp							\
exp: cond_exp '>>=' exp							\
exp: cond_exp '&=' exp							\
exp: cond_exp '^=' exp							\
exp: cond_exp '|=' exp							\
"+"									\
list_exp: exp								\
list_exp: list_exp ',' exp						\
"+"									\
opt_list_exp:								\
opt_list_exp: list_exp							\
"+"									\
arg_list: exp								\
arg_list: arg_list ',' exp						\
"+"									\
opt_arg_list:								\
opt_arg_list: arg_list							\
opt_arg_list: arg_list '...'						\
"+"									\
opt_arg_list_comma:							\
opt_arg_list_comma: arg_list						\
opt_arg_list_comma: arg_list ','					\
"+"									\
assoc_exp: exp ':' exp							\
"+"									\
assoc_arg_list: assoc_exp						\
assoc_arg_list: assoc_arg_list ',' assoc_exp				\
"+"									\
opt_assoc_arg_list_comma:						\
opt_assoc_arg_list_comma: assoc_arg_list				\
opt_assoc_arg_list_comma: assoc_arg_list ','				\
", foo, nalt);
}

mixed *ifelse(mixed *rule)
{
    /*
     * indicate if/else scope with extra bracket pairs
     */
    return ({ "{" }) + rule + ({ "}" });
}


----------------------------------------------------------------------
From felix Fri Feb 13 13:16:19 1998
To: dgd@imaginary.com
Subject: Re: [DGD] parse_string() & removal of ()'s

> This question is in regard to the parse_string() kfun and the omission of
> the ()'s from production rules.  Basically, it's mentioned that functions
> can be used to shape the returned parse tree, but I'm having an extremely
> hard time visualizing it. :)  I guess the best way to ask this question or
> address the issue is to present an example.

And I'll respond with one:

    whitespace = / /
    word = /[a-z]+/

    Thing: Noun
    Thing: SubAdjs Noun
    Noun: word
    Adjs: word Adjs
    Adjs: word
    SubAdjs: Adjs ? do_the_sub_thing

Now for different versions of do_the_sub_thing():

    mixed *do_the_sub_thing(mixed *adjs)
    {
	return ({ adjs });
    }

=> ({ ({ "big", "blue" }), "bottle" })

    mixed *do_the_sub_thing(mixed *adjs)
    {
	return adjs;
    }

=> ({ "big", "blue", "bottle" })

    mixed *do_the_sub_thing(mixed *adjs)
    {
	return ({ });
    }

=> ({ "bottle" })

    mixed *do_the_sub_thing(mixed *adjs)
    {
	return adjs - ({ "blue", "green" });
    }

=> ({ "big", "bottle" })

    mixed *do_the_sub_thing(mixed *adjs)
    {
	return 0;
    }

=> 0

Regards,
Dworkin


-------------------------------------------------------------------------

(From Jason Cone)

For those that are familiar with Lima's implementation of the MudOS verb
parser, this should look familiar.  For those that aren't, here's a brief
summary of how it (mine) works:

* add_rules() defines the grammar rules that the input the player types
should be evaluated with.  General composition of the grammar rules is the
same, but the types of tokens used are different - explained later in this
email.

* The function can_<lowercase rule>() is called with the appropriate
parameters and give the verb a chance to verify whether or not the current
player can successfully use the verb given whatever requirements the verb
coder wishes to impose.  More often that not, returning a 1 will be used.
In fact, if the "can" function doesn't exist, it is assumed that the verb
can be used; returning a 1 and not having the function at all are one in the
same.  It should be noted that the "can" function will only be called if the
parser (parse_string()) is able to match the input with the given rule.  If
the "can" function returns 0, all parsing on the given input will stop.

* The function do_<lowercase rule>() is called with the same parameters as
the matching "can" function.  If this function is called, the parser matched
the input with the rule and the "can" function returned 1 (or didn't exist).
It is here in the "do" function that the action really takes place.  If the
"do" function returns 1, verb parsing stops and command parsing (%%) stops.
If the "do" function returns 0, verb parsing stops, but command parsing
continues.


>In what areas have you made improvements?


Out of not knowing for sure, I will make the assumption that the following
differ (and are good/better things) with respect to MudOS.

* The types of tokens used are different for the most part.  The ones that
are currently supported are: OBJ, OBJI, OBJE, OBJA, LIV, and DIR.  OBJ will
match an object that exists in the player's immediate inventory or immediate
environment.  OBJI will match an object that exists only in the player's
immediate inventory.  OBJE will match an object that exists only in the
player's immediate environment.  OBJA will match any phrase that matches an
ambiguous noun.  The object doesn't need to a loaded physical object - just
have the grammatical syntax of one.  LIV will match an object in the
player's immediate environment that is considered to be living (NPC/monster,
player).  DIR will match a direction.  It is relatively simple to expand the
rule parser to use new tokens - you just need to understand how the
parse_string() kfun works as the actual grammar strings are formed
dynamically.

* I consider an acceptable object syntax to be the following:

  <Optional Preposition> <Optional Article> <Optional Adjectives> <Noun>
<Optional Numerical Identifier>

The OBJA token will return an array with the more important bits of the
above information in the form:

({ ({ <adjective string array> }), <noun string>, <numerical id integer> })

Before the parse_string() kfun was functional, I had a similar system that
employed sscanf() and some rather heinous algorithms to parse grammars.  But
it also accepted numerical identifiers before the noun in word form ("first
ball" as opposed to "ball 1", "sixty-eighth axe" as opposed to "axe 68",
etc.).  This is not yet implemented, but will be soon.

* These same grammars can be used with add_action()-like functions called
triggers.  For those familiar with add_actions() will recognize the
following:

void init()
{
    add_action("test_function", "test");
}

int test_function(sting sInput)
{
    write(sInput + " was input after \"test\"\n");
    return 1;
}

The same thing can be accomplished with my system:

void init()
{
    add_trigger("test");
}

int do_test(string sInput)
{
    write(sInput + " was input after \"test\"\n");
    return 1;
}

The advantage of triggers come into play with the following example:

void init()
{
    add_trigger("test", ({ "OBJA" }));
}

int can_test_obja(mixed *mpObjPacket)
{
    write("Number of adjectives for Ambiguous Object: " +
        sizeof(mpObjPacket[0]) + "\n");
    write("Name of Ambiguous Object: " + mpObjPacket[1] + "\n");
    write("Which Ambiguous Object: " + mpObjPacket[2] + "\n");

    return 1;
}

In other words, triggers <can> be (but don't have to be) object-defined
verbs.  Of course, any number/combination of rules can be used with verbs
and triggers.  Oh, almost forgot.  Each rule is assigned to a 'verbrule'
object (where the parsing is actually done) to take advantage of the
driver-level cachine of parse information for a given grammar.  If the rule
"OBJA on OBJE" is used in 3 different verbs and in 4 triggers, there will
exist only one 'verbrule' object for that rule, not 7.

In short, I think the real advantages of this system over MudOS' are:

* Ability to parse ambigous objects.
* Ability to use parsing functionality on an object level via triggers.
* It's written in LPC, so anyone who understands how parse_string() grammars
are formed can alter/add/remove to their liking.


I hope that made some sort of sense. :)  Specifically, I would like to
solicit suggestions on new token types.  One I'm considering right now is
really just a modification to the OBJ token.  I think it would be useful to
specify an optional search depth via OBJ:2 (would immediate environment,
immediate inventory, and the respective environments/inventories of each of
those).  I don't know, though.  I could see it being useful (as I said), but
I could also see it being a huge performance issue.  It also complicates
rule caching as the number is part of the rule, but isn't used in the
grammar composition - multiple depths should still use one 'verbrule'
object.

(%%) Command parsing in CSLib is done in this order: alias conversion
(player only) -> movement -> verb -> bin (global, then personal) (player
only) -> channel (player only) -> soul -> triggers.

--
  Jason H. Cone
  Dept. Computer Science
  Texas A&M University
  jcone@cs.tamu.edu
